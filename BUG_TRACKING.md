# Bug è¿½è¸ªæ–‡æ¡£ (Bug Tracking Document)

**é¡¹ç›®**: SEO Autopilot - AI Marketing Content System  
**ç‰ˆæœ¬**: 4.1.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-01-28  
**æœ€åæ›´æ–°**: 2026-01-28

---

## ğŸ”´ ä¸¥é‡ Bug (Critical Bugs)

### BUG-001: SEO è‡ªæ£€æ¥å£æœªå®ç°

**ä¼˜å…ˆçº§**: P0 (Critical)  
**çŠ¶æ€**: ğŸ”´ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P0 - åŸºç¡€å‘å¸ƒç³»ç»Ÿ

#### é—®é¢˜æè¿°
æ ¹æ® UPGRADE_ROADMAP.md ä¸­çš„ P0-5 ç¥¨æ®è¦æ±‚ï¼Œåº”è¯¥å®ç°ä¸€ä¸ª SEO è‡ªæ£€æ¥å£ï¼Œç”¨äºéªŒè¯ Rank Math SEO å…ƒæ•°æ®æ˜¯å¦æ­£ç¡®å†™å…¥ã€‚ä½†è¯¥æ¥å£ç›®å‰å®Œå…¨æœªå®ç°ã€‚

#### å¤ç°æ­¥éª¤
1. å¯åŠ¨åç«¯æœåŠ¡: `python -m uvicorn src.api.main:app --reload --port 8080`
2. è®¿é—® Admin Panel: `http://localhost:8080/admin`
3. æŸ¥æ‰¾ "SEO é›†æˆè‡ªæ£€" åŠŸèƒ½
4. **é¢„æœŸ**: åº”è¯¥æœ‰ä¸€ä¸ªæµ‹è¯•æŒ‰é’®ï¼Œå¯ä»¥é€‰æ‹©æ–‡ç« è¿›è¡Œ meta å†™å…¥æµ‹è¯•
5. **å®é™…**: è¯¥åŠŸèƒ½ä¸å­˜åœ¨

#### æŠ€æœ¯ç»†èŠ‚
- **ç¼ºå¤±æ–‡ä»¶**: åº”è¯¥åœ¨ `src/api/admin.py` ä¸­æ·»åŠ  `/api/v1/admin/seo-check` ç«¯ç‚¹
- **é¢„æœŸåŠŸèƒ½**:
  1. æ¥æ”¶ post_id å‚æ•°
  2. å†™å…¥æµ‹è¯• meta æ•°æ®åˆ° WordPress
  3. è¯»å–éªŒè¯æ˜¯å¦æˆåŠŸ
  4. è¿”å›è¯Šæ–­å»ºè®®

#### å½±å“èŒƒå›´
- ç”¨æˆ·æ— æ³•éªŒè¯ Rank Math é›†æˆæ˜¯å¦æ­£ç¡®é…ç½®
- æ— æ³•è¯Šæ–­ SEO å…ƒæ•°æ®å†™å…¥å¤±è´¥çš„åŸå› 
- å¢åŠ é…ç½®éš¾åº¦å’Œè°ƒè¯•æ—¶é—´

#### å»ºè®®ä¿®å¤æ–¹æ¡ˆ

**æ–‡ä»¶**: `src/api/admin.py`

```python
@router.post("/api/v1/admin/seo-check")
async def seo_integration_check(
    post_id: int,
    db: Session = Depends(get_db),
    current_user: dict = Depends(verify_admin)
):
    """
    SEO é›†æˆè‡ªæ£€æ¥å£
    æµ‹è¯• Rank Math meta å†™å…¥å’Œè¯»å–
    """
    try:
        # 1. è·å– WordPress å®¢æˆ·ç«¯
        wp_client = get_wordpress_client()
        
        # 2. å†™å…¥æµ‹è¯• meta
        test_meta = {
            "rank_math_title": "SEO Test Title",
            "rank_math_description": "SEO Test Description",
            "rank_math_focus_keyword": "test keyword"
        }
        
        success = await wp_client.update_post_meta(post_id, test_meta)
        
        # 3. è¯»å–éªŒè¯
        post = await wp_client.get_post(post_id)
        meta = post.get("meta", {})
        
        # 4. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        diagnostics = {
            "write_success": success,
            "meta_found": {
                "title": "rank_math_title" in meta,
                "description": "rank_math_description" in meta,
                "keyword": "rank_math_focus_keyword" in meta
            },
            "values": {
                "title": meta.get("rank_math_title"),
                "description": meta.get("rank_math_description"),
                "keyword": meta.get("rank_math_focus_keyword")
            }
        }
        
        # 5. æä¾›ä¿®å¤å»ºè®®
        if not all(diagnostics["meta_found"].values()):
            diagnostics["recommendation"] = (
                "Rank Math meta fields not accessible via REST API. "
                "Please install the MU plugin to register meta fields. "
                "See docs/rank-math-mu-plugin.php"
            )
        else:
            diagnostics["recommendation"] = "SEO integration is working correctly!"
        
        return diagnostics
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

**å·¥ä½œé‡ä¼°ç®—**: 2-4 å°æ—¶

---

### BUG-002: content_actions è¡¨æœªåˆ›å»º

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸ”´ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P1 - å†…å®¹åˆ·æ–°å’Œ CTR ä¼˜åŒ–

#### é—®é¢˜æè¿°
æ ¹æ® UPGRADE_ROADMAP.md ä¸­çš„ P1-9 ç¥¨æ®ï¼Œåº”è¯¥æœ‰ä¸€ä¸ª `content_actions` è¡¨ç”¨äºè®°å½•å†…å®¹å˜æ›´å†å²ï¼ˆbefore/afterï¼‰ï¼Œä»¥æ”¯æŒå›æ»šåŠŸèƒ½ã€‚ä½†è¯¥è¡¨ç›®å‰æœªåˆ›å»ºã€‚

#### å¤ç°æ­¥éª¤
1. è¿æ¥åˆ°æ•°æ®åº“
2. æŸ¥è¯¢è¡¨åˆ—è¡¨: `SELECT name FROM sqlite_master WHERE type='table';`
3. **é¢„æœŸ**: åº”è¯¥çœ‹åˆ° `content_actions` è¡¨
4. **å®é™…**: è¯¥è¡¨ä¸å­˜åœ¨

#### æŠ€æœ¯ç»†èŠ‚
- **ç¼ºå¤±**: Alembic è¿ç§»è„šæœ¬
- **ç¼ºå¤±**: SQLAlchemy æ¨¡å‹å®šä¹‰

#### æ•°æ®åº“ Schema è®¾è®¡

```sql
CREATE TABLE content_actions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    action_type VARCHAR(50) NOT NULL,  -- 'refresh', 'ctr_optimize', 'title_update', etc.
    post_id INTEGER NOT NULL,
    query VARCHAR(255),
    before_snapshot TEXT,  -- JSON: {title, description, content_excerpt}
    after_snapshot TEXT,   -- JSON: {title, description, content_excerpt}
    reason TEXT,           -- Why this change was made
    metrics_before TEXT,   -- JSON: {position, ctr, impressions, clicks}
    metrics_after TEXT,    -- JSON: same structure (populated after time)
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    applied_by VARCHAR(100),
    rollback_at TIMESTAMP NULL,
    rollback_by VARCHAR(100) NULL,
    status VARCHAR(20) DEFAULT 'active',  -- 'active', 'rolled_back', 'superseded'
    
    INDEX idx_post_id (post_id),
    INDEX idx_action_type (action_type),
    INDEX idx_applied_at (applied_at)
);
```

#### å½±å“èŒƒå›´
- æ— æ³•è¿½è¸ªå†…å®¹å˜æ›´å†å²
- æ— æ³•å®ç°ä¸€é”®å›æ»šåŠŸèƒ½
- æ— æ³•åˆ†æä¼˜åŒ–æ•ˆæœï¼ˆA/B å¯¹æ¯”ï¼‰

#### å»ºè®®ä¿®å¤æ–¹æ¡ˆ

**æ­¥éª¤ 1**: åˆ›å»ºæ¨¡å‹

**æ–‡ä»¶**: `src/models/content_action.py`

```python
from sqlalchemy import Column, Integer, String, Text, DateTime, Index
from sqlalchemy.sql import func
from src.models.base import Base

class ContentAction(Base):
    __tablename__ = "content_actions"
    
    id = Column(Integer, primary_key=True, index=True)
    action_type = Column(String(50), nullable=False, index=True)
    post_id = Column(Integer, nullable=False, index=True)
    query = Column(String(255), nullable=True)
    before_snapshot = Column(Text, nullable=True)  # JSON
    after_snapshot = Column(Text, nullable=True)   # JSON
    reason = Column(Text, nullable=True)
    metrics_before = Column(Text, nullable=True)   # JSON
    metrics_after = Column(Text, nullable=True)    # JSON
    applied_at = Column(DateTime(timezone=True), server_default=func.now())
    applied_by = Column(String(100), nullable=True)
    rollback_at = Column(DateTime(timezone=True), nullable=True)
    rollback_by = Column(String(100), nullable=True)
    status = Column(String(20), default="active")  # active, rolled_back, superseded
    
    __table_args__ = (
        Index('idx_content_actions_post_type', 'post_id', 'action_type'),
        Index('idx_content_actions_applied_at', 'applied_at'),
    )
```

**æ­¥éª¤ 2**: åˆ›å»ºè¿ç§»

```bash
cd c:\Users\DJS Tech\ZenflowProjects\bobopkgproject
alembic revision -m "add_content_actions_table"
```

**å·¥ä½œé‡ä¼°ç®—**: 1-2 å°æ—¶

---

### BUG-003: æœºä¼šæ± åå°ç•Œé¢æœªå®ç°

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸ”´ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P1 - æœºä¼šè¯„åˆ†ç³»ç»Ÿ

#### é—®é¢˜æè¿°
æ ¹æ® UPGRADE_ROADMAP.md ä¸­çš„ P1-6 ç¥¨æ®ï¼Œåº”è¯¥æœ‰ä¸€ä¸ªåå°æœºä¼šæ± ç•Œé¢ï¼Œæ”¯æŒç­›é€‰ã€æ’åºå’Œä¸€é”®æ‰§è¡Œã€‚ä½†è¯¥ç•Œé¢ç›®å‰æœªå®ç°ã€‚

#### å¤ç°æ­¥éª¤
1. è®¿é—® Admin Panel: `http://localhost:8080/admin`
2. æŸ¥æ‰¾ "Opportunity Backlog" æˆ– "æœºä¼šæ± " èœå•
3. **é¢„æœŸ**: åº”è¯¥æœ‰ä¸€ä¸ªé¡µé¢æ˜¾ç¤º SEO æœºä¼šåˆ—è¡¨
4. **å®é™…**: è¯¥é¡µé¢ä¸å­˜åœ¨

#### æŠ€æœ¯ç»†èŠ‚
- **ç¼ºå¤±**: Admin Panel å‰ç«¯é¡µé¢
- **ç¼ºå¤±**: API ç«¯ç‚¹ `/api/v1/opportunities`

#### åŠŸèƒ½éœ€æ±‚

**ç•Œé¢å…ƒç´ **:
1. æœºä¼šåˆ—è¡¨è¡¨æ ¼
   - åˆ—: Query, Position, Impressions, CTR, Score, Action
   - æ’åº: æŒ‰ Score é™åº
   - ç­›é€‰: Position èŒƒå›´, Impressions é˜ˆå€¼
2. æ“ä½œæŒ‰é’®
   - "ç”Ÿæˆå†…å®¹" - åˆ›å»º draft
   - "ä¼˜åŒ– CTR" - ç”Ÿæˆ title/description å€™é€‰
   - "åˆ·æ–°å†…å®¹" - æ›´æ–°ç°æœ‰é¡µé¢
3. æ‰¹é‡æ“ä½œ
   - é€‰æ‹©å¤šä¸ªæœºä¼š
   - æ‰¹é‡ç”Ÿæˆ

#### å½±å“èŒƒå›´
- æ— æ³•å¯è§†åŒ–ç®¡ç† SEO æœºä¼š
- æ— æ³•å¿«é€Ÿæ‰§è¡Œä¼˜åŒ–æ“ä½œ
- é™ä½ç³»ç»Ÿå¯ç”¨æ€§

#### å»ºè®®ä¿®å¤æ–¹æ¡ˆ

**æ–‡ä»¶**: `src/api/opportunities.py` (æ–°å»º)

```python
from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session
from src.core.database import get_db
from src.agents.opportunity_scoring import OpportunityScoringAgent

router = APIRouter(prefix="/api/v1/opportunities", tags=["opportunities"])

@router.get("/")
async def list_opportunities(
    min_position: int = Query(4, ge=1, le=100),
    max_position: int = Query(20, ge=1, le=100),
    min_impressions: int = Query(100, ge=0),
    sort_by: str = Query("score", regex="^(score|impressions|position|ctr)$"),
    limit: int = Query(50, ge=1, le=200),
    db: Session = Depends(get_db)
):
    """
    è·å– SEO æœºä¼šåˆ—è¡¨
    """
    # 1. ä» gsc_queries è¡¨è·å–æ•°æ®
    from src.models.gsc_query import GSCQuery
    
    queries = db.query(GSCQuery).filter(
        GSCQuery.position >= min_position,
        GSCQuery.position <= max_position,
        GSCQuery.impressions >= min_impressions
    ).all()
    
    # 2. ä½¿ç”¨ OpportunityScoringAgent è¯„åˆ†
    agent = OpportunityScoringAgent()
    opportunities = []
    
    for query in queries:
        score = agent.calculate_score({
            "position": query.position,
            "impressions": query.impressions,
            "clicks": query.clicks,
            "ctr": query.ctr
        })
        
        opportunities.append({
            "query": query.query,
            "page": query.page,
            "position": query.position,
            "impressions": query.impressions,
            "clicks": query.clicks,
            "ctr": query.ctr,
            "score": score,
            "recommended_action": agent.recommend_action(score, query.position)
        })
    
    # 3. æ’åº
    opportunities.sort(key=lambda x: x[sort_by], reverse=True)
    
    return {
        "total": len(opportunities),
        "opportunities": opportunities[:limit]
    }

@router.post("/{query_id}/execute")
async def execute_opportunity(
    query_id: int,
    action: str,  # 'generate', 'optimize_ctr', 'refresh'
    db: Session = Depends(get_db)
):
    """
    æ‰§è¡Œæœºä¼šä¼˜åŒ–æ“ä½œ
    """
    # Implementation here
    pass
```

**å·¥ä½œé‡ä¼°ç®—**: 1-2 å¤©

---

### BUG-004: å‘å¸ƒé˜Ÿåˆ—æ§åˆ¶åŠŸèƒ½æœªå®ç°

**ä¼˜å…ˆçº§**: P2 (Medium)  
**çŠ¶æ€**: ğŸ”´ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P2 - pSEO æ‰¹é‡ç”Ÿæˆ

#### é—®é¢˜æè¿°
æ ¹æ® UPGRADE_ROADMAP.md ä¸­çš„ P2-7 ç¥¨æ®ï¼Œæ‰¹é‡å‘å¸ƒåº”è¯¥æ”¯æŒæš‚åœã€æ¢å¤å’Œæ’¤å›åŠŸèƒ½ã€‚ä½†è¿™äº›æ§åˆ¶åŠŸèƒ½ç›®å‰æœªå®ç°ã€‚

#### å¤ç°æ­¥éª¤
1. å¯åŠ¨æ‰¹é‡ç”Ÿæˆä»»åŠ¡
2. å°è¯•æš‚åœä»»åŠ¡
3. **é¢„æœŸ**: åº”è¯¥æœ‰æš‚åœ/æ¢å¤/æ’¤å›æŒ‰é’®
4. **å®é™…**: ä»»åŠ¡ä¸€æ—¦å¯åŠ¨æ— æ³•æ§åˆ¶

#### æŠ€æœ¯ç»†èŠ‚
- **æ–‡ä»¶**: `src/pseo/page_factory.py`
- **ç¼ºå¤±åŠŸèƒ½**: 
  - `pause_batch(batch_id)`
  - `resume_batch(batch_id)`
  - `cancel_batch(batch_id)`
  - `rollback_batch(batch_id)`

#### å½±å“èŒƒå›´
- æ— æ³•ä¸­æ­¢é”™è¯¯çš„æ‰¹é‡ç”Ÿæˆ
- æ— æ³•æ’¤é”€å·²å‘å¸ƒçš„ä½è´¨é‡å†…å®¹
- å¢åŠ è¿è¥é£é™©

#### å»ºè®®ä¿®å¤æ–¹æ¡ˆ

**æ–‡ä»¶**: `src/pseo/page_factory.py`

```python
class BatchJobQueue:
    def __init__(self):
        self.jobs = {}
        self.status = {}  # batch_id -> 'running', 'paused', 'cancelled'
    
    def pause_batch(self, batch_id: str) -> bool:
        """æš‚åœæ‰¹é‡ä»»åŠ¡"""
        if batch_id in self.status:
            self.status[batch_id] = 'paused'
            logger.info(f"Batch {batch_id} paused")
            return True
        return False
    
    def resume_batch(self, batch_id: str) -> bool:
        """æ¢å¤æ‰¹é‡ä»»åŠ¡"""
        if batch_id in self.status and self.status[batch_id] == 'paused':
            self.status[batch_id] = 'running'
            logger.info(f"Batch {batch_id} resumed")
            return True
        return False
    
    def cancel_batch(self, batch_id: str) -> bool:
        """å–æ¶ˆæ‰¹é‡ä»»åŠ¡"""
        if batch_id in self.status:
            self.status[batch_id] = 'cancelled'
            logger.info(f"Batch {batch_id} cancelled")
            return True
        return False
    
    async def rollback_batch(self, batch_id: str, wp_client) -> dict:
        """
        å›æ»šæ‰¹é‡å‘å¸ƒ
        åˆ é™¤æˆ–è®¾ä¸ºè‰ç¨¿
        """
        if batch_id not in self.jobs:
            return {"success": False, "error": "Batch not found"}
        
        job = self.jobs[batch_id]
        published_ids = job.get("published_post_ids", [])
        
        results = {"deleted": 0, "failed": 0}
        
        for post_id in published_ids:
            try:
                # é€‰é¡¹ 1: åˆ é™¤
                # await wp_client.delete_post(post_id)
                
                # é€‰é¡¹ 2: æ”¹ä¸ºè‰ç¨¿
                await wp_client.update_post(post_id, {"status": "draft"})
                results["deleted"] += 1
            except Exception as e:
                logger.error(f"Failed to rollback post {post_id}: {e}")
                results["failed"] += 1
        
        return results
```

**å·¥ä½œé‡ä¼°ç®—**: 4-6 å°æ—¶

---

### BUG-005: ç´¢å¼•ç›‘æ§å®Œå…¨æœªå®ç°

**ä¼˜å…ˆçº§**: P2 (Medium)  
**çŠ¶æ€**: ğŸ”´ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P2 - pSEO å·¥å‚

#### é—®é¢˜æè¿°
æ ¹æ® UPGRADE_ROADMAP.md ä¸­çš„ P2-8 ç¥¨æ®ï¼Œåº”è¯¥å®ç°ç´¢å¼•ä¸æ”¶å½•ç›‘æ§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç«™ç‚¹åœ°å›¾æäº¤ã€IndexNow å’Œæ”¶å½•çŠ¶æ€é¢æ¿ã€‚ä½†è¿™äº›åŠŸèƒ½å®Œå…¨æœªå®ç°ã€‚

#### å¤ç°æ­¥éª¤
1. æ‰¹é‡ç”Ÿæˆé¡µé¢
2. æŸ¥æ‰¾ç´¢å¼•ç›‘æ§åŠŸèƒ½
3. **é¢„æœŸ**: åº”è¯¥èƒ½çœ‹åˆ°æ”¶å½•çŠ¶æ€
4. **å®é™…**: æ— ä»»ä½•ç›‘æ§åŠŸèƒ½

#### æŠ€æœ¯ç»†èŠ‚
- **ç¼ºå¤±**: ç«™ç‚¹åœ°å›¾è‡ªåŠ¨æäº¤
- **ç¼ºå¤±**: IndexNow API é›†æˆ
- **ç¼ºå¤±**: æ”¶å½•çŠ¶æ€é¢æ¿

#### åŠŸèƒ½éœ€æ±‚

1. **ç«™ç‚¹åœ°å›¾æäº¤**
   - ç”Ÿæˆ sitemap.xml
   - è‡ªåŠ¨æäº¤åˆ° Google Search Console
   - æäº¤åˆ° Bing Webmaster Tools

2. **IndexNow é›†æˆ**
   - æ–°é¡µé¢å‘å¸ƒåç«‹å³é€šçŸ¥æœç´¢å¼•æ“
   - æ”¯æŒæ‰¹é‡æäº¤

3. **æ”¶å½•çŠ¶æ€é¢æ¿**
   - æ˜¾ç¤ºå·²å‘å¸ƒ vs å·²æ”¶å½•æ•°é‡
   - æ˜¾ç¤ºæ”¶å½•ç‡è¶‹åŠ¿
   - æ ‡è®°æœªæ”¶å½•é¡µé¢

#### å½±å“èŒƒå›´
- æ— æ³•è¿½è¸ªé¡µé¢æ”¶å½•æƒ…å†µ
- æ— æ³•åŠ é€Ÿç´¢å¼•è¿‡ç¨‹
- æ— æ³•è¯†åˆ«ç´¢å¼•é—®é¢˜

#### å»ºè®®ä¿®å¤æ–¹æ¡ˆ

**æ–‡ä»¶**: `src/integrations/indexnow.py` (æ–°å»º)

```python
import httpx
from typing import List

class IndexNowClient:
    """
    IndexNow API å®¢æˆ·ç«¯
    æ”¯æŒ Google, Bing, Yandex ç­‰
    """
    
    ENDPOINTS = [
        "https://www.bing.com/indexnow",
        "https://api.indexnow.org/indexnow"
    ]
    
    def __init__(self, api_key: str, host: str):
        self.api_key = api_key
        self.host = host
    
    async def submit_urls(self, urls: List[str]) -> dict:
        """
        æäº¤ URL åˆ° IndexNow
        """
        payload = {
            "host": self.host,
            "key": self.api_key,
            "urlList": urls
        }
        
        results = []
        async with httpx.AsyncClient() as client:
            for endpoint in self.ENDPOINTS:
                try:
                    resp = await client.post(
                        endpoint,
                        json=payload,
                        headers={"Content-Type": "application/json"}
                    )
                    results.append({
                        "endpoint": endpoint,
                        "status": resp.status_code,
                        "success": resp.status_code == 200
                    })
                except Exception as e:
                    results.append({
                        "endpoint": endpoint,
                        "error": str(e),
                        "success": False
                    })
        
        return {
            "submitted_urls": len(urls),
            "results": results
        }
```

**å·¥ä½œé‡ä¼°ç®—**: 2-3 å¤©

---

## ğŸŸ¡ é‡è¦ Bug (Major Bugs)

### BUG-006: job_runs å®¡è®¡æ—¥å¿—ä¸å¤Ÿè¯¦ç»†

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸŸ¡ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P0 - ä»»åŠ¡è°ƒåº¦

#### é—®é¢˜æè¿°
å½“å‰çš„ job_runs è®°å½•ä¸å¤Ÿè¯¦ç»†ï¼Œç¼ºå°‘è¾“å…¥/è¾“å‡ºå¿«ç…§ï¼Œå¯¼è‡´è°ƒè¯•å›°éš¾ã€‚

#### å»ºè®®ä¿®å¤
åœ¨ `src/scheduler/job_runner.py` ä¸­å¢å¼ºæ—¥å¿—è®°å½•ï¼š

```python
class JobRun(Base):
    __tablename__ = "job_runs"
    
    id = Column(Integer, primary_key=True)
    job_name = Column(String(100), nullable=False)
    input_snapshot = Column(Text, nullable=True)  # æ–°å¢: JSON
    output_snapshot = Column(Text, nullable=True)  # æ–°å¢: JSON
    error_detail = Column(Text, nullable=True)
    error_traceback = Column(Text, nullable=True)  # æ–°å¢: å®Œæ•´å †æ ˆ
    started_at = Column(DateTime, server_default=func.now())
    completed_at = Column(DateTime, nullable=True)
    status = Column(String(20))  # success, failed, timeout
    retry_count = Column(Integer, default=0)  # æ–°å¢: é‡è¯•æ¬¡æ•°
```

**å·¥ä½œé‡ä¼°ç®—**: 4-6 å°æ—¶

---

### BUG-007: GSC æ•°æ®æºçŠ¶æ€é¡µæœªå®ç°

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸŸ¡ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P1 - GSC é›†æˆ

#### é—®é¢˜æè¿°
æ ¹æ® P1-3 ç¥¨æ®ï¼Œåº”è¯¥æœ‰ä¸€ä¸ªæ•°æ®æºè¿æ¥çŠ¶æ€é¡µï¼Œæ˜¾ç¤ºé…é¢ã€æœ€è¿‘åŒæ­¥æ—¶é—´å’Œé”™è¯¯æç¤ºã€‚

#### å»ºè®®ä¿®å¤
åœ¨ Admin Panel ä¸­æ·»åŠ  "Data Sources" é¡µé¢ï¼š

**API ç«¯ç‚¹**: `/api/v1/gsc/status`

```python
@router.get("/status")
async def gsc_status(db: Session = Depends(get_db)):
    """
    GSC è¿æ¥çŠ¶æ€å’Œé…é¢ä¿¡æ¯
    """
    try:
        gsc_client = get_gsc_client()
        
        # è·å–é…é¢ä¿¡æ¯ (Google API é™åˆ¶)
        quota_info = {
            "daily_limit": 2000,  # GSC API æ¯æ—¥é™åˆ¶
            "used_today": await get_daily_usage(db),
            "remaining": 2000 - await get_daily_usage(db)
        }
        
        # æœ€è¿‘åŒæ­¥æ—¶é—´
        last_sync = db.query(GSCQuery).order_by(
            GSCQuery.date.desc()
        ).first()
        
        return {
            "connected": True,
            "quota": quota_info,
            "last_sync": last_sync.date if last_sync else None,
            "total_queries": db.query(GSCQuery).count(),
            "health": "healthy" if quota_info["remaining"] > 100 else "warning"
        }
    except Exception as e:
        return {
            "connected": False,
            "error": str(e),
            "health": "error"
        }
```

**å·¥ä½œé‡ä¼°ç®—**: 1 å¤©

---

### BUG-008: TopicMap ä¸ºç®€åŒ–ç‰ˆæœ¬

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸŸ¡ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P1 - å†…é“¾å¼•æ“

#### é—®é¢˜æè¿°
å½“å‰çš„ TopicMap æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œç¼ºå°‘å®Œæ•´çš„ Hub/Spoke å…³ç³»ç®¡ç†ï¼Œå¯¼è‡´å†…é“¾ç­–ç•¥ä¸å¤Ÿæ™ºèƒ½ã€‚

#### å»ºè®®å¢å¼º

**æ–‡ä»¶**: `src/agents/internal_linking.py`

```python
class TopicMap:
    """
    å®Œæ•´çš„ä¸»é¢˜å›¾è°±
    æ”¯æŒ Hub/Spoke å…³ç³»å’Œæ„å›¾åˆ†ç»„
    """
    
    def __init__(self):
        self.hubs = {}  # hub_id -> Hub
        self.spokes = {}  # spoke_id -> Spoke
        self.intent_groups = {}  # intent -> [post_ids]
    
    def add_hub(self, post_id: int, title: str, intent: str):
        """æ·»åŠ æ”¯æŸ±é¡µ (Hub)"""
        self.hubs[post_id] = {
            "title": title,
            "intent": intent,
            "spokes": [],
            "authority_score": 0.0
        }
    
    def add_spoke(self, post_id: int, title: str, hub_id: int):
        """æ·»åŠ è¾å°„é¡µ (Spoke)"""
        self.spokes[post_id] = {
            "title": title,
            "hub_id": hub_id
        }
        if hub_id in self.hubs:
            self.hubs[hub_id]["spokes"].append(post_id)
    
    def detect_cannibalization(self, intent: str) -> List[dict]:
        """
        æ£€æµ‹å…³é”®è¯èš•é£Ÿ
        åŒæ„å›¾å¤šé¡µé¢ç«äº‰æ£€æµ‹
        """
        posts = self.intent_groups.get(intent, [])
        if len(posts) > 1:
            return [{
                "intent": intent,
                "conflicting_posts": posts,
                "recommendation": "merge or set canonical"
            }]
        return []
    
    def recommend_internal_links(self, post_id: int, count: int = 5) -> List[dict]:
        """
        æ¨èå†…é“¾
        ä¼˜å…ˆé“¾æ¥åˆ° Hubï¼Œç„¶åæ˜¯ç›¸å…³ Spokes
        """
        links = []
        
        # 1. å¦‚æœæ˜¯ Spokeï¼Œå¿…é¡»é“¾æ¥åˆ° Hub
        if post_id in self.spokes:
            hub_id = self.spokes[post_id]["hub_id"]
            links.append({
                "target_id": hub_id,
                "anchor_text": self.hubs[hub_id]["title"],
                "reason": "hub_link"
            })
        
        # 2. é“¾æ¥åˆ°ç›¸å…³ Spokes
        # (åŸºäºæ„å›¾ç›¸ä¼¼åº¦)
        
        return links[:count]
```

**å·¥ä½œé‡ä¼°ç®—**: 2-3 å¤©

---

### BUG-009: QualityGateAgent åŠŸèƒ½ä¸å®Œæ•´

**ä¼˜å…ˆçº§**: P2 (Medium)  
**çŠ¶æ€**: ğŸŸ¡ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P2 - pSEO è´¨é‡æ§åˆ¶

#### é—®é¢˜æè¿°
QualityGateAgent çš„ç›¸ä¼¼åº¦æ£€æµ‹å’Œä¿¡æ¯å¢é‡éªŒè¯åŠŸèƒ½ä¸å®Œæ•´ã€‚

#### å»ºè®®å¢å¼º

```python
from difflib import SequenceMatcher
from typing import List, Dict

class QualityGateAgent:
    """
    è´¨é‡é—¨ç¦ Agent
    é˜²æ­¢ä½è´¨é‡å’Œé‡å¤å†…å®¹
    """
    
    SIMILARITY_THRESHOLD = 0.85  # 85% ç›¸ä¼¼åº¦è§†ä¸ºé‡å¤
    MIN_MODULES_REQUIRED = 3     # è‡³å°‘åŒ…å« 3 ä¸ªä¿¡æ¯æ¨¡å—
    
    async def check_similarity(self, new_content: str, existing_contents: List[str]) -> dict:
        """
        æ£€æŸ¥å†…å®¹ç›¸ä¼¼åº¦
        """
        max_similarity = 0.0
        most_similar = None
        
        for idx, existing in enumerate(existing_contents):
            similarity = SequenceMatcher(None, new_content, existing).ratio()
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar = idx
        
        return {
            "max_similarity": max_similarity,
            "is_duplicate": max_similarity > self.SIMILARITY_THRESHOLD,
            "most_similar_index": most_similar,
            "threshold": self.SIMILARITY_THRESHOLD
        }
    
    async def check_information_value(self, page_data: dict) -> dict:
        """
        æ£€æŸ¥ä¿¡æ¯å¢é‡
        ç¡®ä¿é¡µé¢åŒ…å«è¶³å¤Ÿçš„ç‹¬ç‰¹æ¨¡å—
        """
        modules = page_data.get("modules", [])
        module_types = set([m["type"] for m in modules])
        
        required_types = {"summary", "table", "faq"}
        has_required = required_types.issubset(module_types)
        
        return {
            "module_count": len(modules),
            "unique_types": len(module_types),
            "has_required_modules": has_required,
            "missing_modules": list(required_types - module_types),
            "passed": len(modules) >= self.MIN_MODULES_REQUIRED and has_required
        }
    
    async def execute(self, page_data: dict, context: dict) -> dict:
        """
        æ‰§è¡Œè´¨é‡æ£€æŸ¥
        """
        # 1. ç›¸ä¼¼åº¦æ£€æŸ¥
        similarity_result = await self.check_similarity(
            page_data["content"],
            context.get("existing_contents", [])
        )
        
        # 2. ä¿¡æ¯å¢é‡æ£€æŸ¥
        value_result = await self.check_information_value(page_data)
        
        # 3. ç»¼åˆåˆ¤æ–­
        passed = (
            not similarity_result["is_duplicate"] and
            value_result["passed"]
        )
        
        return {
            "passed": passed,
            "similarity_check": similarity_result,
            "value_check": value_result,
            "recommendation": self._generate_recommendation(
                similarity_result, value_result
            )
        }
    
    def _generate_recommendation(self, sim: dict, val: dict) -> str:
        if sim["is_duplicate"]:
            return f"Content too similar ({sim['max_similarity']:.1%}). Add unique information."
        if not val["passed"]:
            return f"Add more modules. Missing: {', '.join(val['missing_modules'])}"
        return "Quality check passed."
```

**å·¥ä½œé‡ä¼°ç®—**: 2-3 å¤©

---

### BUG-010: å½’å› åˆ†æç¼ºå°‘ ROI å›å†™

**ä¼˜å…ˆçº§**: P3 (Low)  
**çŠ¶æ€**: ğŸŸ¡ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28  
**å½±å“æ¨¡å—**: P3 - è½¬åŒ–è¿½è¸ª

#### é—®é¢˜æè¿°
å½“å‰çš„å½’å› åˆ†ææ˜¯åŸºç¡€å®ç°ï¼Œç¼ºå°‘ ROI è®¡ç®—å’Œå›å†™åˆ°æœºä¼šè¯„åˆ†çš„åŠŸèƒ½ã€‚

#### å»ºè®®å¢å¼º

```python
class ConversionTracker:
    async def calculate_roi(self, page_url: str, time_range: tuple) -> dict:
        """
        è®¡ç®—é¡µé¢ ROI
        """
        # 1. è·å–è¯¥é¡µé¢çš„è½¬åŒ–äº‹ä»¶
        conversions = self.get_conversions_by_page(page_url, time_range)
        
        # 2. è®¡ç®—æ”¶å…¥ (å‡è®¾æœ‰è®¢å•æ•°æ®)
        revenue = sum([c.revenue for c in conversions if c.revenue])
        
        # 3. è®¡ç®—æˆæœ¬ (å†…å®¹ç”Ÿæˆ token æˆæœ¬)
        cost = self.get_content_cost(page_url)
        
        # 4. ROI
        roi = (revenue - cost) / cost if cost > 0 else 0
        
        return {
            "page_url": page_url,
            "revenue": revenue,
            "cost": cost,
            "roi": roi,
            "conversion_count": len(conversions)
        }
    
    async def update_opportunity_score(self, page_url: str, roi: float):
        """
        å°† ROI å›å†™åˆ°æœºä¼šè¯„åˆ†
        é«˜ ROI é¡µé¢åº”è¯¥ä¼˜å…ˆåˆ·æ–°å’Œä¼˜åŒ–
        """
        # æ›´æ–° OpportunityScore è¡¨
        # æˆ–è€…è°ƒæ•´ OpportunityScoringAgent çš„æƒé‡
        pass
```

**å·¥ä½œé‡ä¼°ç®—**: 3-5 å¤©

---

## ğŸŸ¢ æ¬¡è¦ Bug (Minor Bugs)

### BUG-011: éƒ¨åˆ†è¡¨ç¼ºå°‘ç´¢å¼•

**ä¼˜å…ˆçº§**: P2 (Medium)  
**çŠ¶æ€**: ğŸŸ¢ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28

#### é—®é¢˜æè¿°
éƒ¨åˆ†æ•°æ®åº“è¡¨ç¼ºå°‘ç´¢å¼•ï¼Œå¯èƒ½å½±å“æŸ¥è¯¢æ€§èƒ½ã€‚

#### å»ºè®®æ·»åŠ ç´¢å¼•

```sql
-- gsc_queries è¡¨
CREATE INDEX idx_gsc_queries_position ON gsc_queries(position);
CREATE INDEX idx_gsc_queries_impressions ON gsc_queries(impressions);
CREATE INDEX idx_gsc_queries_date_query ON gsc_queries(date, query);

-- job_runs è¡¨
CREATE INDEX idx_job_runs_status ON job_runs(status);
CREATE INDEX idx_job_runs_started_at ON job_runs(started_at);
```

**å·¥ä½œé‡ä¼°ç®—**: 1-2 å°æ—¶

---

### BUG-012: WP MU æ’ä»¶æ–‡æ¡£ç¼ºå¤±

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: ğŸŸ¢ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28

#### é—®é¢˜æè¿°
ç¼ºå°‘ WordPress MU æ’ä»¶ç¤ºä¾‹ï¼Œç”¨æˆ·ä¸çŸ¥é“å¦‚ä½•å¯ç”¨ Rank Math meta çš„ REST API è®¿é—®ã€‚

#### å»ºè®®æ·»åŠ æ–‡æ¡£

**æ–‡ä»¶**: `docs/rank-math-mu-plugin.php`

```php
<?php
/**
 * Plugin Name: Rank Math REST API Enabler
 * Description: Enable Rank Math meta fields in WordPress REST API
 * Version: 1.0.0
 */

add_action('init', function() {
    // Register Rank Math meta fields for REST API
    $meta_fields = [
        'rank_math_title',
        'rank_math_description',
        'rank_math_focus_keyword',
        'rank_math_robots',
        'rank_math_canonical_url'
    ];
    
    foreach ($meta_fields as $field) {
        register_meta('post', $field, [
            'show_in_rest' => true,
            'single' => true,
            'type' => 'string',
            'auth_callback' => function() {
                return current_user_can('edit_posts');
            }
        ]);
    }
});
```

**å®‰è£…è¯´æ˜**:
1. å°†æ­¤æ–‡ä»¶å¤åˆ¶åˆ° `wp-content/mu-plugins/` ç›®å½•
2. å¦‚æœ `mu-plugins` ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
3. æ— éœ€æ¿€æ´»ï¼ŒMU æ’ä»¶è‡ªåŠ¨åŠ è½½

**å·¥ä½œé‡ä¼°ç®—**: 30 åˆ†é’Ÿ

---

### BUG-013: èš•é£Ÿæ£€æµ‹ä»…åŸºç¡€å®ç°

**ä¼˜å…ˆçº§**: P2 (Medium)  
**çŠ¶æ€**: ğŸŸ¢ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28

#### é—®é¢˜æè¿°
å½“å‰çš„å…³é”®è¯èš•é£Ÿæ£€æµ‹è¿‡äºç®€å•ï¼Œå¯èƒ½é—æ¼å¤æ‚çš„å†²çªæƒ…å†µã€‚

#### å»ºè®®å¢å¼º
- åŸºäº TF-IDF çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹
- è€ƒè™‘ URL ç»“æ„ç›¸ä¼¼åº¦
- åˆ†æ GSC æ•°æ®ä¸­çš„æ’åæ³¢åŠ¨

**å·¥ä½œé‡ä¼°ç®—**: 2-3 å¤©

---

### BUG-014: Backlink Copilot åŠŸèƒ½ç®€åŒ–

**ä¼˜å…ˆçº§**: P3 (Low)  
**çŠ¶æ€**: ğŸŸ¢ Open  
**å‘ç°æ—¥æœŸ**: 2026-01-28

#### é—®é¢˜æè¿°
Backlink Copilot ä¸ºåŸºç¡€å®ç°ï¼Œéœ€è¦å¢å¼ºæœºä¼šå‘ç°å’Œ outreach è‡ªåŠ¨åŒ–ã€‚

#### å»ºè®®å¢å¼º
- é›†æˆ Ahrefs/SEMrush API å‘ç°æœºä¼š
- è‡ªåŠ¨åŒ–é‚®ä»¶å‘é€ (SMTP é›†æˆ)
- CRM å¼çš„çŠ¶æ€è·Ÿè¸ª

**å·¥ä½œé‡ä¼°ç®—**: 5-7 å¤©

---

## âš™ï¸ é…ç½®é—®é¢˜ (Configuration Issues)

### CFG-001: .env ç¼ºå°‘ WordPress é…ç½®

**ä¼˜å…ˆçº§**: P0 (Critical)  
**çŠ¶æ€**: âš™ï¸ Open

#### é—®é¢˜
`.env` æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„ WordPress é…ç½®ã€‚

#### è§£å†³æ–¹æ¡ˆ
åœ¨ `.env.example` ä¸­æ·»åŠ :

```bash
# WordPress Integration (Required for P0)
WORDPRESS_URL=https://your-wordpress-site.com
WORDPRESS_USERNAME=your_wp_username
WORDPRESS_PASSWORD=your_wp_app_password
```

---

### CFG-002: .env ç¼ºå°‘ Redis é…ç½®

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: âš™ï¸ Open

#### é—®é¢˜
`.env` æ–‡ä»¶ç¼ºå°‘ Redis é…ç½®ï¼Œä¸”æ²¡æœ‰é™çº§æ–¹æ¡ˆã€‚

#### è§£å†³æ–¹æ¡ˆ
1. åœ¨ `.env.example` ä¸­æ·»åŠ :
```bash
# Redis (Optional - for caching and queue)
REDIS_URL=redis://localhost:6379/0
```

2. åœ¨ä»£ç ä¸­æ·»åŠ é™çº§é€»è¾‘:
```python
try:
    redis_client = redis.from_url(settings.redis_url)
    redis_client.ping()
except:
    logger.warning("Redis not available, using in-memory cache")
    redis_client = None  # ä½¿ç”¨å†…å­˜ç¼“å­˜
```

---

### CFG-003: ç¼ºå°‘ç¤ºä¾‹é…ç½®æ–‡ä»¶

**ä¼˜å…ˆçº§**: P1 (High)  
**çŠ¶æ€**: âš™ï¸ Open

#### é—®é¢˜
`.env.example` ä¸å¤Ÿå®Œæ•´ï¼Œç¼ºå°‘è¯¦ç»†è¯´æ˜ã€‚

#### è§£å†³æ–¹æ¡ˆ
å®Œå–„ `.env.example`ï¼Œæ·»åŠ æ‰€æœ‰å¿…è¦é…ç½®å’Œæ³¨é‡Šã€‚

---

## ğŸ“Š Bug ç»Ÿè®¡

### æŒ‰ä¼˜å…ˆçº§

- **P0 (Critical)**: 3 ä¸ª
- **P1 (High)**: 6 ä¸ª
- **P2 (Medium)**: 4 ä¸ª
- **P3 (Low)**: 2 ä¸ª
- **é…ç½®é—®é¢˜**: 3 ä¸ª

### æŒ‰çŠ¶æ€

- **ğŸ”´ Open**: 5 ä¸ª (ä¸¥é‡)
- **ğŸŸ¡ Open**: 5 ä¸ª (é‡è¦)
- **ğŸŸ¢ Open**: 4 ä¸ª (æ¬¡è¦)
- **âš™ï¸ Open**: 3 ä¸ª (é…ç½®)

### æŒ‰æ¨¡å—

- **P0 åŸºç¡€å‘å¸ƒ**: 3 ä¸ª
- **P1 GSC é©±åŠ¨**: 5 ä¸ª
- **P2 pSEO å·¥å‚**: 4 ä¸ª
- **P3 è½¬åŒ–é—­ç¯**: 2 ä¸ª
- **åŸºç¡€è®¾æ–½**: 1 ä¸ª
- **é…ç½®**: 3 ä¸ª

---

## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§å»ºè®®

### æœ¬å‘¨ (Week 1)
1. CFG-001, CFG-002, CFG-003 - é…ç½®é—®é¢˜
2. BUG-001 - SEO è‡ªæ£€æ¥å£
3. BUG-002 - content_actions è¡¨
4. BUG-012 - WP MU æ’ä»¶æ–‡æ¡£

### ä¸‹å‘¨ (Week 2)
5. BUG-003 - æœºä¼šæ± ç•Œé¢
6. BUG-006 - å®¡è®¡æ—¥å¿—å¢å¼º
7. BUG-007 - GSC çŠ¶æ€é¡µ
8. BUG-011 - æ•°æ®åº“ç´¢å¼•

### ä¸¤å‘¨å (Week 3-4)
9. BUG-004 - å‘å¸ƒé˜Ÿåˆ—æ§åˆ¶
10. BUG-008 - TopicMap å¢å¼º
11. BUG-009 - QualityGate å¢å¼º
12. BUG-013 - èš•é£Ÿæ£€æµ‹å¢å¼º

### ä¸€ä¸ªæœˆå (Month 1)
13. BUG-005 - ç´¢å¼•ç›‘æ§
14. BUG-010 - ROI å›å†™
15. BUG-014 - Backlink Copilot å¢å¼º

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Antigravity AI  
**æœ€åæ›´æ–°**: 2026-01-28  
**ä¸‹æ¬¡å®¡æŸ¥**: 2026-02-04
